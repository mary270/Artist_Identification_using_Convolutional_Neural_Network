{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-googlenet",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c004fc6f23ec4af2a5703ff6a20278d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3338efa802d44e7f8b42ef6999500003",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d45eac41c09f4697a734b0e95c3fe7a9",
              "IPY_MODEL_ae8671ccda894c629ec3e5713c9d2339"
            ]
          }
        },
        "3338efa802d44e7f8b42ef6999500003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d45eac41c09f4697a734b0e95c3fe7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f8ba50406537458e8a356eb6c46ff5e2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 52147035,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 52147035,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fc811ea34f64869b29f9ee9a44fb49e"
          }
        },
        "ae8671ccda894c629ec3e5713c9d2339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_14dcc08745fc4edea3b51ab4f2e735a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49.7M/49.7M [00:00&lt;00:00, 272MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26bfe5ae50bb46a8bd28f36442a3be8b"
          }
        },
        "f8ba50406537458e8a356eb6c46ff5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fc811ea34f64869b29f9ee9a44fb49e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14dcc08745fc4edea3b51ab4f2e735a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26bfe5ae50bb46a8bd28f36442a3be8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XclBgEbUTGgU",
        "outputId": "88d4c19c-9ae2-4099-eb62-c8b67cd8c4a9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Biu_d1D1WOtk"
      },
      "source": [
        "DATASET_FOLDER = \"/content/drive/MyDrive/Datasets/images/images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwBwFyN9XKmv"
      },
      "source": [
        "## Imports Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMGo_KotXIyI"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, utils\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl6p27GdXI__",
        "outputId": "014ee4f3-04da-41b8-be0c-b7fc22734d4b"
      },
      "source": [
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n",
            "0.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJwmw9eDXZHy"
      },
      "source": [
        "## ImageFolder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHyIEbYoXX-j"
      },
      "source": [
        "datasetImageFolder = torchvision.datasets.ImageFolder(DATASET_FOLDER, transform=transforms.Compose([\n",
        "                                               transforms.Resize((299, 299)),\n",
        "                                               transforms.ToTensor(),\n",
        "                                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])                                                     \n",
        "]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2-XvAuIYa9C",
        "outputId": "d24d8df9-e587-4c8d-9c16-9f234257fd07"
      },
      "source": [
        "print(datasetImageFolder.classes)\n",
        "print('total classes', len(datasetImageFolder.classes))\n",
        "print('total iamges', len(datasetImageFolder))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Albrecht_DuÔòá├¬rer', 'Albrecht_Du╠êrer', 'Alfred_Sisley', 'Amedeo_Modigliani', 'Andrei_Rublev', 'Andy_Warhol', 'Camille_Pissarro', 'Caravaggio', 'Claude_Monet', 'Diego_Rivera', 'Diego_Velazquez', 'Edgar_Degas', 'Edouard_Manet', 'Edvard_Munch', 'El_Greco', 'Eugene_Delacroix', 'Francisco_Goya', 'Frida_Kahlo', 'Georges_Seurat', 'Giotto_di_Bondone', 'Gustav_Klimt', 'Gustave_Courbet', 'Henri_Matisse', 'Henri_Rousseau', 'Henri_de_Toulouse-Lautrec', 'Hieronymus_Bosch', 'Jackson_Pollock', 'Jan_van_Eyck', 'Joan_Miro', 'Kazimir_Malevich', 'Leonardo_da_Vinci', 'Marc_Chagall', 'Michelangelo', 'Mikhail_Vrubel', 'Pablo_Picasso', 'Paul_Cezanne', 'Paul_Gauguin', 'Paul_Klee', 'Peter_Paul_Rubens', 'Pierre-Auguste_Renoir', 'Piet_Mondrian', 'Pieter_Bruegel', 'Raphael', 'Rembrandt', 'Rene_Magritte', 'Salvador_Dali', 'Sandro_Botticelli', 'Titian', 'Vasiliy_Kandinskiy', 'Vincent_van_Gogh', 'William_Turner']\n",
            "total classes 51\n",
            "total iamges 8785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eUHLfdiapl8",
        "outputId": "1c58cd11-91e7-4a4c-fa85-220c50fcb926"
      },
      "source": [
        "train_size = round(0.9 * len(datasetImageFolder))\n",
        "test_size = len(datasetImageFolder) - train_size\n",
        "print(train_size, test_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7906 879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e66Y8300aWE8"
      },
      "source": [
        "batch_size = 32\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(datasetImageFolder, [train_size, test_size])\n",
        "\n",
        "traindl = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "testdl = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRil1Pw0N8Xm"
      },
      "source": [
        "#Googlenet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvUSQ1VBeOmY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "c004fc6f23ec4af2a5703ff6a20278d8",
            "3338efa802d44e7f8b42ef6999500003",
            "d45eac41c09f4697a734b0e95c3fe7a9",
            "ae8671ccda894c629ec3e5713c9d2339",
            "f8ba50406537458e8a356eb6c46ff5e2",
            "8fc811ea34f64869b29f9ee9a44fb49e",
            "14dcc08745fc4edea3b51ab4f2e735a9",
            "26bfe5ae50bb46a8bd28f36442a3be8b"
          ]
        },
        "outputId": "594c82b1-a18c-40be-9996-f986431edcd9"
      },
      "source": [
        "googlenet = torchvision.models.googlenet(pretrained=True, progress=True)\n",
        "googlenet.fc = torch.nn.Linear(1024, 51)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c004fc6f23ec4af2a5703ff6a20278d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=52147035.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX7pAS_VhRcP"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "googlenet = googlenet.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzuGCoj4lSId"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uqcPZKde42w"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(googlenet.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8e7SYJLZdAN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccomuSiQOHYi"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9mszRmyf2N8"
      },
      "source": [
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(traindl, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = googlenet(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 50 == 49:    # print every 50 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 50))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpJRSPQIOLAq"
      },
      "source": [
        "#Pytorch model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AunicisaZgtV"
      },
      "source": [
        "ONNX_PATH=\"./meraArtistWalaModel.onnx\"\r\n",
        "TF_PATH = \"./meraArtistWalaModel.pb\" # where the representation of tensorflow model will be stored\r\n",
        "TFLITE_PATH = \"./meraArtistWalaModel.tflite\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO_he7zhxusG"
      },
      "source": [
        "PATH = './artistifyModel.pt'\n",
        "torch.save(googlenet.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BhX5ZWaOZu_"
      },
      "source": [
        "#ONNX model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh_6eBo0ON-E"
      },
      "source": [
        "import onnx\r\n",
        "import torch\r\n",
        "\r\n",
        "example_input = torch.random((1, 3, 299, 299))\r\n",
        " # exmample for the forward pass input \r\n",
        "pytorch_model = googlenet\r\n",
        "\r\n",
        "torch.onnx.export(\r\n",
        "    model=pytorch_model,\r\n",
        "    args=example_input, \r\n",
        "    f=ONNX_PATH, # where should it be saved\r\n",
        "    verbose=False,\r\n",
        "    export_params=True,\r\n",
        "    do_constant_folding=False,  # fold constant values for optimization\r\n",
        "    # do_constant_folding=True,   # fold constant values for optimization\r\n",
        "    input_names=['input'],\r\n",
        "    output_names=['output']\r\n",
        ")\r\n",
        "onnx_model = onnx.load(ONNX_PATH)\r\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x3KyjhvPcUX"
      },
      "source": [
        "#Tensorflow model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWQWAZNHQHsF"
      },
      "source": [
        "from onnx_tf.backend import prepare\r\n",
        "import onnx\r\n",
        "\r\n",
        "\r\n",
        "onnx_model = onnx.load(ONNX_PATH)  # load onnx model\r\n",
        "\r\n",
        "# prepare function converts an ONNX model to an internel representation\r\n",
        "# of the computational graph called TensorflowRep and returns\r\n",
        "# the converted representation.\r\n",
        "tf_rep = prepare(onnx_model)  # creating TensorflowRep object\r\n",
        "\r\n",
        "# export_graph function obtains the graph proto corresponding to the ONNX\r\n",
        "# model associated with the backend representation and serializes\r\n",
        "# to a protobuf file.\r\n",
        "tf_rep.export_graph(TF_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjgVmgddUsrC"
      },
      "source": [
        "#Tensorflowlite model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGmAX6XBUvvE"
      },
      "source": [
        "\r\n",
        "# protopuf needs your virtual environment to be explictly exported in the path\r\n",
        "os.environ[\"PATH\"] = \"/opt/miniconda3/envs/convert/bin:/opt/miniconda3/bin:/usr/local/sbin:....\"\r\n",
        "\r\n",
        "# make a converter object from the saved tensorflow file\r\n",
        "converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(TF_PATH,  # TensorFlow freezegraph .pb model file\r\n",
        "                                                      input_arrays=['input'], # name of input arrays as defined in torch.onnx.export function before.\r\n",
        "                                                      output_arrays=['output'] # name of output arrays defined in torch.onnx.export function before.\r\n",
        "                                                      )\r\n",
        "\r\n",
        "# tell converter which type of optimization techniques to use\r\n",
        "# to view the best option for optimization read documentation of tflite about optimization\r\n",
        "# go to this link https://www.tensorflow.org/lite/guide/get_started#4_optimize_your_model_optional\r\n",
        "# converter.optimizations = [tf.compat.v1.lite.Optimize.DEFAULT]\r\n",
        "\r\n",
        "converter.experimental_new_converter = True\r\n",
        "\r\n",
        "# I had to explicitly state the ops\r\n",
        "converter.target_spec.supported_ops = [tf.compat.v1.lite.OpsSet.TFLITE_BUILTINS,\r\n",
        "                                       tf.compat.v1.lite.OpsSet.SELECT_TF_OPS]\r\n",
        "\r\n",
        "tf_lite_model = converter.convert()\r\n",
        "# Save the model.\r\n",
        "with open(TFLITE_PATH, 'wb') as f:\r\n",
        "    f.write(tf_lite_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}